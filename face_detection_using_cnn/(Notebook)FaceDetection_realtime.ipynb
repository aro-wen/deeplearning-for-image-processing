{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904de6a3",
   "metadata": {},
   "source": [
    "# Real-Time Face Detection with OpenCV DNN (Webcam)\n",
    "\n",
    "This notebook demonstrates **real-time face detection** using OpenCV's Deep Neural Network (DNN) module and your systemâ€™s webcam.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Why CNN?\n",
    "\n",
    "We use a CNN-based face detection model trained using the SSD (Single Shot Multibox Detector) framework.\n",
    "\n",
    "- The model predicts **bounding boxes and confidence scores** in a single pass.\n",
    "- Itâ€™s based on a **ResNet-10** backbone, a lightweight convolutional neural network.\n",
    "- This allows fast and efficient real-time face detection, even on CPU.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Files Used\n",
    "- `deploy.prototxt`: Defines CNN architecture.\n",
    "- `res10_300x300_ssd_iter_140000_fp16.caffemodel`: Pre-trained CNN weights.\n",
    "\n",
    "Make sure both files are in your working directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ee360",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "- `cv2`: OpenCV library for video capture, DNN operations, and drawing.\n",
    "- `sys`: Allows reading command-line arguments (e.g., video file paths), but optional in notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0934d2c",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Video Source\n",
    "\n",
    "- `cv2.VideoCapture(0)` opens the default webcam.\n",
    "- You can also provide a path to a video file via command line (`sys.argv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1effa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default camera (0) or a video path if passed via command line\n",
    "s = 0\n",
    "if len(sys.argv) > 1:\n",
    "    s = sys.argv[1]\n",
    "\n",
    "source = cv2.VideoCapture(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019e153",
   "metadata": {},
   "source": [
    "## Step 3: Load CNN Model and Define Parameters\n",
    "\n",
    "- Load the model architecture and weights.\n",
    "- Set preprocessing parameters for the CNN:\n",
    "  - Input size: `300x300`\n",
    "  - Mean subtraction: `[104, 117, 123]` (standard for this model)\n",
    "  - Confidence threshold: only show detections with score > 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9fb65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_name = 'Camera Preview'\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Load the pre-trained CNN face detector\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "# Model input size and settings\n",
    "in_width = 300\n",
    "in_height = 300\n",
    "mean = [104, 117, 123]\n",
    "conf_threshold = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf341c",
   "metadata": {},
   "source": [
    "## Step 4: Run Real-Time Detection Loop\n",
    "\n",
    "- The loop runs until you press the **Esc key** (`cv2.waitKey(1) != 27`).\n",
    "- Each frame is flipped horizontally (`cv2.flip(frame, 1)`) for a selfie effect.\n",
    "- We convert the frame to a blob, pass it to the CNN, and extract detections.\n",
    "- For detections with confidence > 0.7:\n",
    "  - Bounding box is drawn.\n",
    "  - Confidence label is shown above the box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342b9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cv2.waitKey(1) != 27:  # Press 'Esc' to exit\n",
    "    has_frame, frame = source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "\n",
    "    # Mirror the frame (like a selfie view)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Create blob for CNN input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (in_width, in_height), mean, swapRB=False, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run forward pass to detect faces\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Loop through detections\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "            y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "            x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "            y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw confidence label\n",
    "            label = f\"Confidence: {confidence:.4f}\"\n",
    "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1 - label_size[1]),\n",
    "                                (x1 + label_size[0], y1 + base_line),\n",
    "                                (255, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "    # Measure and display inference time\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "    # Show the result in a window\n",
    "    cv2.imshow(win_name, frame)\n",
    "\n",
    "# Cleanup after loop ends\n",
    "source.release()\n",
    "cv2.destroyWindow(win_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff455507",
   "metadata": {},
   "source": [
    "## Step 5: Show Output and Release Resources\n",
    "\n",
    "- Display the frame with bounding boxes and **inference time**.\n",
    "- When done (after pressing Esc), release the video stream and close the window.\n",
    "\n",
    "### ðŸ’¡ Tip\n",
    "In notebooks, displaying OpenCV windows can be tricky. For a better notebook experience, consider writing the frame to disk or converting it to a format viewable with `matplotlib`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
